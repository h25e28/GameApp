{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  深層モデルの訓練のための最適化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深層モデルの学習に用いられる最適化アルゴリズムと従来の最適化アルゴリズムについての違いを紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習と純粋な最適化の差異"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 経験損失最小化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習アルゴリズムの最終目的は、汎化誤差（学習して獲得したサンプルの母集団に対する誤差）を小さくすることです。そのために、以下のように経験損失を最小化します。<br>\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{x,y}[L(f(x;θ),y)] = \\frac{1}{m}\\sum^m_{i=1}L(f(x^{(i)};θ),y^{(i)})\n",
    "$$\n",
    "\n",
    "この学習過程を**経験損失最小化**といいます。経験損失を最小化しても、サンプリングされたデータによっては期待損失（汎化誤差）が小さくなるとは限らない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代理損失関数と早期終了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　代理損失関数を最適化することは元の関数の代替として機能します。分類である0/1損失関数を例に説明します。2クラス分類における正解データは-1か1のいずれかです。この時の損失関数は次のように示します。<br><br>\n",
    "$$\n",
    "L(t,f(w,x))=0 if t=sign(f(w,x))else 1\n",
    "$$<br><br>\n",
    " sign(u)とはuの符号が負なら「-1」、正なら「1」を返す関数とします。この式は「正解ラベルtと出力f(w,x)の富豪が一致しているならば損失は0（分類成功）、一致しなければ損失は１」という意味です。<br>\n",
    "　つまり、f(w,x)が限りなく大きい数値で正に分類されても、限りなく小さい数値で正と分類されても構わないということになります。こういった問題を解決するために、代理損失関数が使われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### バッチアルゴリズムとミニバッチアルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの学習を行う際、一度にモデルに渡す入力データの数は変えることができます。一度に渡すデータの数を、バッチサイズといい、バッチサイズ毎に学習をすることを**バッチ学習**といいます。<br>\n",
    "一度に複数のデータを渡した時、モデルはそれぞれのデータでの損失と損失関数の勾配（重みをどのように更新するべきか）を求め、求めた勾配の平均を使ってパラメータの更新を行います。<br>\n",
    "例：データが1000個あるとした時、\n",
    "- ランダムに取り出したデータ1つ毎に学習をする手法をオンライン学習（確率的勾配降下法）（バッチサイズ＝１）\n",
    "- 1000個の全データ毎に学習をする手法をバッチ学習（最急降下法）（バッチサイズ=1000）\n",
    "- ランダムに取り出した1~1000個のバッチ毎に学習をする手法をミニバッチ学習(バッチサイズ=1~1000)\n",
    "と言います。\n",
    "<br><br>\n",
    "**ミニバッチ学習はオンライン学習とバッチ学習の良い点をとった手法**です。バッチを使うことの利点は<br>\n",
    "- 複数のデータを用いて平均化された重みの更新を行うことで、極端に変わったデータの影響をあまり受けずに済む。\n",
    "- 並列計算が行えるので、GPUを用いることで計算時間を短縮することができる。<br>\n",
    "が挙げられます。\n",
    "\n",
    "$$\n",
    "\\theta = \\theta – \\eta \\cdot \\nabla_\\theta J( \\theta; x^{(i:i+n)}; y^{(i:i+n)})\n",
    "$$\n",
    "\n",
    "ミニバッチ学習では、このようにパラメータ更新の分散を減らし、より安定した収束へ導きます。そして、ミニバッチに関する勾配の計算を効果的に行う、高度に最適化された行列最適化を活用します。\n",
    "\n",
    "モデルパラメータ\n",
    "$\\theta \\in \\mathbb{R}^d$\n",
    "\n",
    "トレーニングデータセット全体に対するパラメータ\n",
    "$(\\theta)$\n",
    "\n",
    "目的関数\n",
    "$J(\\theta)$\n",
    "\n",
    "目的関数の勾配方向\n",
    "$\\nabla_\\theta J(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ミニバッチ学習について、次の選択肢のうちから、正しいものを選んでください。<br>\n",
    "1. ミニバッチ学習では、バッチごとに最も良いデータを1つ取り出し、そのデータを使ってパラメータを更新する。\n",
    "1. ミニバッチ学習では、エポック毎の学習で同じミニバッチデータを使用する。\n",
    "1. ミニバッチ学習を採用することで精度を向上させることができるが、オンライン学習などに比べて計算時間が大幅に大きくなってしまう。\n",
    "1. ミニバッチ学習では、複数のデータを用いて平均化された重みの更新を行うため、極端に変わったデータの影響をあまり受けずに済む。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ミニバッチ学習では、複数のデータを用いて平均化された重みの更新を行うため、極端に変わったデータの影響をあまり受けずに済む。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 実装問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の空白を埋めて実装してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ミニバッチ学習を実装するために10000回の学習に関して、訓練データと学習データをスライスしたものを入れた。\n",
    "#その実装を以下のコードに示す。\n",
    "\n",
    "num_epoch = 10000\n",
    "num_data = train_x.shape[0]\n",
    "batch_size = 32\n",
    "for epoch in range(num_epoch):\n",
    "    for idx in range(0, num_data, batch_size):\n",
    "        batch_x = train_x[idx: idx + batch_size if idx + batch_size < num_data else num_data]\n",
    "        batch_t = train_t[idx: idx + batch_size if idx + batch_size < num_data else num_data]\n",
    "        sess.run(train_step, feed_dict = {X: batch_x, t: batch_t})\n",
    "        \n",
    "#しかし上記の実装では、ミニバッチに入るデータが毎回同じになってしまうため、\n",
    "#ミニバッチ学習とは言えない。そのため、ミニバッチに入る32個のデータをランダムにしなければならない。\n",
    "#そのため、以下のコードに変更し、ミニバッチ学習を実装したい。空欄に入る記号を答えよ。\n",
    "        \n",
    "num_epoch = 10000\n",
    "num_data = train_x.shape[0]\n",
    "batch_size = 32\n",
    "for epoch in range(num_epoch):\n",
    "    sff_idx = #（あ）\n",
    "    for idx in range(0, num_data, batch_size):\n",
    "        batch_x = #（い）\n",
    "        batch_t = \n",
    "        sess.run(train_step, feed_dict = {X: batch_x, t: batch_t})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_epoch = 10000\n",
    "num_data = train_x.shape[0]\n",
    "batch_size = 32\n",
    "for epoch in range(num_epoch):\n",
    "    sff_idx = np.random.permutation(num_data)\n",
    "    for idx in range(0, num_data, batch_size):\n",
    "        batch_x = train_x[sff_idx[idx: idx + batch_size \n",
    "            if idx + batch_size < num_data else num_data]]\n",
    "        batch_t = train_t[sff_idx[idx: idx + batch_size\n",
    "            if idx + batch_size < num_data else num_data]]\n",
    "        sess.run(train_step, feed_dict = {X: batch_x, t: batch_t})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 実装問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の空白を埋めて実装してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練例を何度も反復するのではなく、サイズ50のミニバッチを反復します。\n",
    "for i in range(nb_epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch in get_batches(data, batch_size=50):\n",
    "        params_grad = evaluate_gradient(loss_function, batch, params)\n",
    "        #（あ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練例を何度も反復するのではなく、サイズ50のミニバッチを反復します。\n",
    "for i in range(nb_epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch in get_batches(data, batch_size=50):\n",
    "        params_grad = evaluate_gradient(loss_function, batch, params)\n",
    "        params = params - learning_rate * params_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワーク最適化課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このパートでは、深層学習の最適化に関わる最も有名な課題について学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 悪条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "悪条件はニューラルネットワークの訓練問題に基本的には存在します。非常に小さなステップでもコスト関数が増加するということにより、悪条件が顕在化することがあります。<br>\n",
    "悪条件はニューラルネットワークの学習以外でも存在しますが、そのような場合に用いられる対処法をニューラルネットワークに適用することは難しいです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 局所的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "極小点は、最小値と比較して極小点が高いコストを保つ場合に問題となります。隠れ層なしでも最小値より高いコストの極小値を持つ小さなニューラルネットワークを構成することが可能です。<br>\n",
    "高いコストを持つ極小値が共通である場合は、勾配の基づいた最適化アルゴリズムにおいて深刻な問題が生じる可能性があります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プラトー、鞍点、その他平坦な領域"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高次の非凸関数の多くでは、勾配が0になる点（鞍点）と比較すると極小点または極大点は珍しいです。鞍点では、ヘッセ行列は正負両方の固有値を持ちます。正の固有値に関連付けられた固有ベクトルに沿って位置する点は、鞍点よりもコストが高く、負の固有値に沿って位置する点はコストが低くなります。**鞍点は、コスト関数のある断面に沿った極小値で、別の断面に沿った極大値であると捉えることができます。**<br>\n",
    "ランダム関数のクラスの多くは、低次元で極小値が多い、高次元で極小値は少ない、鞍点は一般的にみられる、といった挙動を示します。ランダム関数は、コストの低い領域に近づくにつれて、ヘッセ行列の固有値が正になる可能性が高まるという性質があります。<br>\n",
    "コストの高い臨界点は鞍点である可能性がはるかに高く、コストが極めて高い臨界点は最大値である可能性の方が高くなります"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 崖と勾配爆発"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多層のニューラルネットワークは大きな重みをいくつも掛け合わせた結果、急峻な崖に似た領域を持つことが多くなります。<br>\n",
    "きわめて急峻な崖の構造の表面では、勾配の更新ステップがパラメータを非常に遠くまで動かしてしまう場合があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 長期依存性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算グラフが深くなる場合、ニューラルネットワークの最適化アルゴリズムが解決すべき課題が生じます。多層の順伝播型ネットワーク、回帰結合型ネットワークは深いグラフを持ちます。そして、長い時系列の各ステップで同じ操作を繰り返し適用するので、非常に深い計算グラフが生じます。同じパラメータを繰り返し適用すると、特にはっきりした問題が生じます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  不正確な勾配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ほとんどの最適化アルゴリズムは、正確な**勾配やヘッセ行列を利用できるという前提**で設計されていますが、実際はこれにノイズが加わったり、バイアスが含まれる推定しか得られないのが一般的です。<br>\n",
    "深層学習のアルゴリズムがサンプリングに基づく推定に依存していて、訓練事例のミニバッチを使って勾配を計算しています。目的関数が扱いにくい場合は、勾配も扱いにくいのが一般的です。その場合は勾配を近似することしかできません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本的なアルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このパートでは、機械学習全般において、使用頻度の高いアルゴリズムについて学びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 確率的勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークの重みの更新は誤差逆伝播により求まる誤差関数の勾配方向に更新されます。このとき、一回の更新に用いられるデータの数によって呼ばれ方が異なります。各名称は次の通りです。<br>\n",
    "\n",
    "|名称|内容|\n",
    "|:-:|:-|\n",
    "|最急降下法|全データを用いて求めた勾配に基づいて更新|\n",
    "|確率的勾配降下法|i番目のデータから求めた勾配で更新を$i=1, ..., N$に対して行う(Nはデータ数)|\n",
    "|ミニバッチ学習|幾つかのデータに対して求めた勾配に基づいて更新を全データを使うまで行う|\n",
    "<br>\n",
    "　**最急降下法**は全データを用いるため、同じ位置の**勾配は変わりません**。そのため、一度局所解に収束してしまうと抜け出せなくなるという問題があります。<br>\n",
    "　これに対して、確率的勾配降下法では**同じ位置でも勾配が変化**するので、**局所解に陥りにくくなります**。ただし、1つのデータしか用いないため、それが外れ値であった場合は間違った方向に更新してしまいます。<br>\n",
    "　この問題を減らせるのがミニバッチ学習です。ミニバッチ学習ではいくつかのデータを使うため、**外れ値の影響が小さく**なります。このとき、一度に使うデータ数は自動では求まらないため決める必要があり、大きくしすぎると最急降下法に近くなり、小さくすると確率的勾配降下法に近くなります。<br>\n",
    "　確率的勾配降下法（SGD）とその派生形は、機械学習、深層学習において最もよく用いられる最適化アルゴリズムです。学習率を作用させ勾配の逆方向にパラメータを変化させるアルゴリズムは次で表される。\n",
    " \n",
    "$$\n",
    "{W ← W - \\eta{\\frac{{\\partial}L}{{\\partial}W}}\n",
    "}\n",
    "$$\n",
    "\n",
    "- 学習率$\\eta$\n",
    "- Wに関する損失関数の勾配${\\frac{{\\partial}L}{{\\partial}W}}$\n",
    "- パラメータ$W$\n",
    "- 交差エントロピー誤差$L$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のアルゴリズムの特徴について、確率的勾配降下法を説明しているのはどれか。\n",
    "1. 1つのデータを用いるため、同じ位置でも勾配が変化するので局所解に陥りにくい。\n",
    "2. 任意数の事例についてミニバッチの勾配の平均をとることで、勾配の普遍推定を得れる。\n",
    "3. 全データのうち、いずれかのデータを使うため、外れ値の影響が小さくなる。\n",
    "4. 指数関数的に減衰する過去の勾配の移動平均を蓄積し、継続的に勾配へ進む"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 1つのデータを用いるため、同じ位置でも勾配が変化するので局所解に陥りにくい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　固定の学習率ϵをSGDは時間とともに学習率を徐々に減少させる必要があるのでk回目の反復時点の学習率ϵ_kとする。これは、SGD勾配推定量が最小値に到達しても消失しないノイズの発生源となっているためである。SGDの収束を保証する十分条件は次のうちどれか。\n",
    "$$\n",
    "1.  \\sum^\\infty_{k=1}\\in_k=\\infty,and \\sum ^\\infty _{k=1}\\in_k^2< \\infty\n",
    "$$\n",
    "$$\n",
    " 2. \\sum^\\infty_{k=1}\\in_k<\\infty,and \\sum ^\\infty _{k=1}\\in_k^2< \\infty\n",
    "$$\n",
    "$$\n",
    "3. \\sum^\\infty_{k=1}\\in_k=\\infty,and \\sum ^\\infty _{k=1}\\in_k^2= \\infty\n",
    "$$\n",
    "$$\n",
    "4. \\sum^\\infty_{k=1}\\in_k<\\infty,and \\sum ^\\infty _{k=1}\\in_k^2  \\ll  \\infty\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "1. \\sum^\\infty_{k=1}\\in_k=\\infty,and \\sum ^\\infty _{k=1}\\in_k^2< \\infty\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 実装問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の空白を埋めて実装してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#最適化処理の基底クラス\n",
    "class Optimizer:\n",
    "    def __init__(self, name, learning_rate = 0.01):#learning_rate: 学習率\n",
    "        self.name = name\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        return\n",
    "\n",
    "#確率的勾配降下法（SGD）\n",
    "class SGD(Optimizer):\n",
    "    #初期化\n",
    "    def __init__(self):\n",
    "        super().__init__('SGD')\n",
    "    \n",
    "    #更新\n",
    "    def update(self, params, grads): #params:重みパラメータ grads:勾配\n",
    "        for key in params.keys():\n",
    "            #（あ）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解答\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#最適化処理の基底クラス\n",
    "class Optimizer:\n",
    "    def __init__(self, name, learning_rate = 0.01):#learning_rate: 学習率\n",
    "        self.name = name\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        return\n",
    "\n",
    "#確率的勾配降下法（SGD）\n",
    "class SGD(Optimizer):\n",
    "    #初期化\n",
    "    def __init__(self):\n",
    "        super().__init__('SGD')\n",
    "    \n",
    "    #更新\n",
    "    def update(self, params, grads): #params:重みパラメータ grads:勾配\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.learning_rate * grads[key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モメンタム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率的勾配降下法はよく使われる最適化戦略ですが、学習が遅くなる場合があります。<br>\n",
    "モメンタム法は、学習を高速化するために設計されていて、特に曲率が高い場合、小さく一定の勾配の場合、またはノイズが含まれる勾配に直面した場合に用いられます。モメンタムアルゴリズムは、指数関数的に減衰する過去の勾配の移動平均を蓄積し、継続的にその勾配の方向に進むようにします。<br>\n",
    "モメンタム法は、主に2つの問題を解決することを目的としています。１つはヘッセ行列の悪条件で、もう1つは確率的勾配降下法の分散です。\n",
    "<img src='https://aidemyexstorage.blob.core.windows.net/aidemycontents/1535070519523699.jpg' width=300>\n",
    "<center>図16</center>\n",
    "図16はモメンタム法によって1つ目の問題がどのように解決されるかを示しています。<br>\n",
    "楕円の線は、悪条件のヘッセ行列の二次損失関数を表しています。楕円を横切る経路は、モメンタム法の学習則に従ってこの関数が最小化されるときに、それがたどる経路を示しています。途中の各ステップにおいて、その点で勾配降下法が取るステップを示す矢印を描いています。<br>\n",
    "悪条件の二次目的関数は、両側が急峻な細長い谷または警告の狭い幅を行き来して時間を浪費しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ネステロフのモメンタム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネステロフの加速勾配法に着想を得たモメンタムアルゴリズムの派生形の更新則は以下で与えられます。<br>\n",
    "<img src='https://aidemyexstorage.blob.core.windows.net/aidemycontents/1535070997073360.png' width=400>\n",
    "ただし、パラメータ$α$と$ϵ$は標準的なモメンタム法と似た役割を果たします。ネステロフのモメンタムと通常のモメンタムの違いは、どこで勾配が評価されるかにあります。ネステロフのモメンタムでは現在の速度が適用された後で勾配が評価されます。<br>\n",
    "したがって、ネステロフのモメンタムは標準的なモメンタムに修正要因を追加しようとしていると解釈できます。<br>\n",
    "凸バッチ勾配の場合、ネステロフのモメンタムは、超過誤差の収束率をO(1/$k$)（$k$ステップの後）からO(1/$k^2$)に動かします。<br>\n",
    "しかし、確率的勾配降下法の場合には、ネステロフのモメンタムでは収束率は改善されません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータの初期化戦略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このパートでは、パラメータの初期化戦略として、初期の重み設定、バイアス設定の理想的な値を理解することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　深層学習モデルの学習アルゴリズムは反復的であるため、反復を開始する初期点をユーザーが指定する必要があります。選択された定数を各ユニットのバイアスとして設定し、モデル内の重み全てを、ガウス分布または、一様分布からランダムに抽出された値に初期化します。初期分布の大きさは、最適化手順の結果とネットワークの汎化性能の両方に大きな影響を与えます。<br>\n",
    "　初期の重みが大きいほど、対称性の破れの効果は大きくなり、冗長なユニットの回避、各層の線形成分を通過する順伝播または逆伝播において信号が失われるのを防ぐことに役立ちます。<br>\n",
    "　つまり、行列の値が大きいほど行列積の出力は大きな値となります。しかし、初期の重みが大きすぎると、順伝播、逆伝播中に値が爆発するかもしれません。回帰型ネットワークでは、大きな重みによってカオス（入力の小さな摂動に対して極端に敏感なため、決定論的な順伝播処理の挙動がランダムに見える状態）に陥る可能性もあります。勾配爆発問題は、勾配クリッピング（勾配降下法のステップを実行する前に、勾配の値を閾値で制限する）によってある程度緩和されます。<br>\n",
    "　大きな重みは、活性化関数を飽和させる極端な値になってしまう可能性があり、それによって飽和したユニットでの完全な勾配消失が生じます。これらの競合する要素から、初期の重みの理想的な大きさが決まります。<br><br>\n",
    "　バイアスの設定に関するアプローチは、重みの設定に関するアプローチと連携させる必要があります。一般的な戦略は、教師なしモデルで学習したパラメータで教師ありモデルを初期化することです。このときは、同じ入力を使って学習するか若しくは、関連するタスクで教師あり学習を行うこともできます。また、関連のないタスクで教師あり学習を行うことでも、無作為な初期化より早い収束をもたらす初期化が可能な場合があります。<br><br>\n",
    "　このような初期化戦略の中には、分布に関する情報を符号化してモデルの初期パラメータに取り組むことで、収束を速くして汎化性能を向上させるものがあります。また、パラメータが正しいスケールを持つように設定します。<br>\n",
    "　あるいはユニットによって互いに異なる関数の計算をするように設定することで、明らかに良い性能が発揮されるものもあります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 適応的な学習率を持つアルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルパラメータの学習率を適応させる増分法の中からいくつかのアルゴリズムを簡単に説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaGradアルゴリズムは学習係数を自動で調整してくれることが強みです。重みの更新は以下の式のように行います。パラメータ$\\epsilon$は、無限大に発散させないように小さな正の定数を設定します。\n",
    "\n",
    "$$\n",
    "{h_{0} = \\epsilon\\\\\n",
    "h_{t} = h_{t−１} + \\nabla E(\\mathbf{w}^{t})^{2}\\\\\n",
    "\\eta_{t} = \\frac{\\eta_{0}}{\\sqrt{h_{t}}}\\\\\n",
    "\\mathbf{w}^{t+1} = \\mathbf{w}^{t} - \\eta_{t} \\nabla E(\\mathbf{w}^{t})\n",
    "}\n",
    "$$\n",
    "\n",
    "エポック回数を重ねていくごとに計算される学習係数$η_t$は小さくなっていくことが分かります。また、傾きが小さくなっていく毎に$η_t$は0に漸近していき収束することも期待できます。\n",
    "\n",
    "凸最適化の場合、AdaGradアルゴリズムは、望ましい理論的性質を持ちます。しかしながら、経験的には、深層ニューラルネットワークモデルの学習において、学習の最初から勾配の二乗の累計を計算することは、事実上の学習率の早すぎる過剰な減少を招く可能性があります。<br>\n",
    "AdaGradが良好な性能を発揮する場合はありますが、あらゆる深層学習モデルでうまくいくというわけではありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSPropアルゴリズムではAdaGradを修正し、勾配の累計を指数関数的な重みを付けた移動平均に変更することで、非凸の条件下でAdaGradの性能を改善しています。<br>\n",
    "重みの更新は以下の式のように行います。\n",
    "\n",
    "$$\n",
    "{h_{t} = \\alpha h_{t−１} + (1 - \\alpha) \\nabla E(\\mathbf{w}^{t})^{2}\\\\\n",
    "\\eta_{t} = \\frac{\\eta_{0}}{\\sqrt{h_{t}} + \\epsilon}\\\\\n",
    "\\mathbf{w}^{t+1} = \\mathbf{w}^{t} - \\eta_{t} \\nabla E(\\mathbf{w}^{t})\\\\\n",
    "}\n",
    "$$\n",
    "\n",
    "初期値は$h_0=0$です。αによって過去の勾配の影響を抑えるとともに、新しい$h_t$を優先して反映させるという効果を狙っているのがAddGradからの最大の変更点です。これにより、AdaGradでは過去の勾配情報を全て均等に考慮して計算が行われていましたが、より直近の勾配情報を優先して計算するという改良が実現されています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adamはさらに別の適応的学習率最適化アルゴリズムです。<br>\n",
    "Adam、RMSprop、Adagradの中で最もよく使われるのはAdamなので、最初はAdamを用いて学習し、精度が高くならない場合などに他の方法に変更すると良いです。<br>\n",
    "RMSpropとの違いが、２つあります。<br>\n",
    "1. Adamでは、モメンタムは勾配(指数関数的な重み付けのある)一次モーメントの推定として直接導入される点です。\n",
    "1. Adamには一次モーメント(モメンタム項)と中心化されていない二次モーメントの両方の推定へのバイアス補正が含まれており、原点での初期化が考慮されている点です。RMSpropにも中心化されていない二次モーメントは学習の初期においてバイアスが大きくなる可能性があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二次手法の近似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深層ニューラルネットワークの学習に、二次手法を適用することについて説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ニュートン法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニュートン法は2次の勾配まで考慮しているため、1次の勾配のみを考慮している最急降下法よりも最適解に効率よく到達することができます。ニュートン法の仕組みについて次に示します。<br>\n",
    "- 点$x_n$の次の点を$x_{n+1} =θ$として最適な解を逐次的に求める。\n",
    "- $x_{n+1}$は以下のように決める<br>\n",
    "　1.　勾配方向$d$を決める<br>\n",
    "　2.　$f(x - αd)$を最小にする$α$を決める<br>\n",
    "　3.　$x_n + αd$を$x_{n+1}$とする<br>\n",
    "\n",
    "最適化した関数を$f(θ_0)$とする。この関数を二次テイラー級数展開で近似した式を次に示します。<br>\n",
    "\n",
    "$$\n",
    "f(x+\\Delta x) \\approx f(x) + \\Delta x^{\\rm{T}} \\nabla f(x) + \\frac{1}{2} \\Delta x^{\\rm{T}} (\\nabla^2 f(x)) \\Delta x\n",
    "$$\n",
    "\n",
    "ここで、$g_n=\\nabla f(x_n)$は点$x$における勾配で、$H_n=\\nabla^2 f(x_n)$は点$x$におけるヘッセ行列です。\n",
    "上の展開式を書き直すと、\n",
    "\n",
    "$$\n",
    "h(\\Delta x) \\approx \\Delta x^{\\rm{T}} {\\mathbf g_n} + \\frac{1}{2} \\Delta x^{\\rm{T}} {\\bf H}_\\rm{n} \\Delta x\n",
    "$$\n",
    "\n",
    "この式を最小化するΔxを求めたいので、両辺をΔxで微分すると\n",
    "\n",
    "$$\n",
    "\\frac{\\partial h_n(\\Delta x)}{\\partial \\Delta x} = {\\mathbf g_n} +  {\\mathbf H_n} \\Delta x\n",
    "$$\n",
    "\n",
    "になります。\n",
    "\n",
    "これが0になるとき$h_n(\\Delta x)$は最小値をとるので、その時の$Δx$を求めると次式になります。\n",
    "\n",
    "$$\n",
    "\\Delta x = -{\\bf H}_n^{-1} {\\bf g}_n\n",
    "$$\n",
    "\n",
    "ここで求めたΔxを探索方向とします。\n",
    "\n",
    "二次でない表面については、ヘッセ行列が正定値である限り、ニュートン法を反復的に適用できます。これには、逆ヘッセ行列を更新または計算（二次近似を計算）後に、パラメータを更新という2段階の反復手順が必要になります。<br>\n",
    "深層学習において、一般的に目的関数の表面は、鞍点のような**多くの特徴を持つ**非凸面であり、それがニュートン法にとっては問題となります。たとえば鞍点近傍でヘッセ行列の固有値すべてが正でない場合、ニュートン法は間違った方向に移動するように更新してしまう可能性があります。<br>\n",
    "この状況は**ヘッセ行列を正則化**することで回避できます。よく用いられる正則化戦略としては、ヘッセ行列の体格要素に定数$α$を加算する方法があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 共役勾配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "共役勾配は、反復的に降下する共役方向によって、逆ヘッセ行列の計算を効率的に可否回避する手法です。共役勾配法では、直前の直線探索の方向に対して共役な探索方向を求めることを試みます。<br>\n",
    "二次曲面において、共役方向は、直前の方向に対して勾配の大きさが増加しないことを保証するため、直前の方向について最小値にとどまります。<br>\n",
    "その結果、$ｋ$次元のパラメータ空間においては、共役勾配で最小値に到達するまでに、最大で$ｋ$回の直線探索が必要となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BFGSアルゴリズムは、計算量の負荷なしでニュートン法の利点を活用しようとするものです。\n",
    "\n",
    "ニュートン法の更新は、次式で与えられます。\n",
    "<img src='https://aidemyexstorage.blob.core.windows.net/aidemycontents/1535072107645384.png' width='400'>\n",
    "ただし、$H$は、$\\theta_0$で評価される$\\theta$に関する$J$のヘッセ行列です。<br>\n",
    "準ニュートン法（BFGSアルゴリズムが最も有名）で採用されるアプローチは、$H^{-1}$のよい近似となるように低ランクの更新によって反復的に改良した行列$M_t$を使って、逆行列を近似する方法です。<br>\n",
    "一度逆ヘッセ行列の近似$M_t$が更新されると、降下方向$ρ_t$は$ρ_t=M_t g_t$によって決定されます。この方向のステップ幅$ϵ^*$を決定するため、この方向で直線探索を実行します。パラメータへの最終的に更新は以下で与えられます。\n",
    "<img src='https://aidemyexstorage.blob.core.windows.net/aidemycontents/1535072313011433.png' width=400>\n",
    "共役勾配法と同様に、BFGSアルゴリズムでは二次の情報を含む方向へ一連の直線探索を繰り返します。BFGSは直線探索のたびに行う改善のため時間が少なく済むという利点があります。<br>\n",
    "一方で、BFGSアルゴリズムでは$O（n^{2}）$のメモリ量を必要とする逆ヘッセ行列Mを保持する必要があり、そのため、一般的に数百万ものパラメータを持つ現代の深層モデルのほとんどに対して、BFGSを利用することは現実的ではありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化戦略とメタアルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アルゴリズムを生成することに特化できる汎用のテンプレート、異なるアルゴリズムに組み込めるサブルーチンなどの最適化テクニックを学ぶことができます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### バッチ正規化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチ正規化は、**勾配爆発・消失**を防ぎ、ネットワークプロセスを全体的に安定させて学習速度を高めることに成功しています。具体的には、内部共変量シフトを減らす効果があります。<br>\n",
    "内部共変量シフトとは、入力の分布が異なる現象を意味します。Deep Networkでは、深くなった隠れ層において各層と活性化層ごとに、入力された分布が変わってしまうことが問題となり、こちらが内部共変量シフトと呼ばれています。<br>\n",
    "そこで、バッチ正規化を適用することにより、学習時のミニバッチごとに各レイヤーの要素ごとに正規化して内部共変量シフトを減らすことができます。<br>\n",
    "これにより勾配爆発・消失の懸念が少なくなるため、学習率を高く設定することで学習が早く進み、また重みの初期値に敏感にならずにすみます。<br>\n",
    "パッチ正規化はデータの前処理としてだけではなく、中間層の出力に適用することができます。特に、活性化関数**ReLU**など、出力値の範囲が限定されていない関数の出力に対してバッチ正規化を使うと、学習がスムーズに進みやすくなり大きな効果を発揮します。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 実装問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalization():\n",
    "    a = np.array([1.,2.,3.])    # ベクトルaの生成\n",
    "    b = a / np.linalg.norm(a)   # ベクトルの正規化\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 教師あり事前学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題を多くの要素に分解し、その要素ごとに個別に最適な要素を求めるという貪欲法を使った事前学習アルゴリズムのことを貪欲教師あり事前学習と言います。最初の貪欲教師あり事前学習（Bengio et al.,2007）では、各段階は最終的なニューラルネットワークの層の一部だけが関わります。教師あり学習の訓練タスクで構成されています。例を図17に示します。<br>\n",
    "この図では、追加された隠れ層はそれぞれ浅い教師ありMLPの一部として事前学習したもので、以前に学習した隠れ層の出力を入力として受け取っています。\n",
    "<img src='https://aidemyexstorage.blob.core.windows.net/aidemycontents/1535073316488417.jpg' width=350>\n",
    "<center>図17</center>\n",
    "<br>\n",
    "図17の各役割については次に示します。<br>\n",
    "(a)十分に浅いアーキテクチャを訓練することから始めています。<br>\n",
    "(b)同じアーキテクチャを別な形で表したものです。<br>\n",
    "(c)元のネットワークの入力層から隠れ層までだけを残し、隠れ層から出力層までのを破棄します。隠れ層の出力を別の教師ありの隠れ層への入力として送ることで第2の隠れ層を追加します。これを必要な層の数だけ繰り返します。<br>\n",
    "(d)結果を別の形で表した順伝播ネットワークです。最適化をさらに改善するために、全ての層をまとめて再学習できます。<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
